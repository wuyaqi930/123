# 自己训练的神经网络
网络结构：四层全连接层，每层128个神经元 
激活函数：Relu
优化器：Adam
学习率：0.0003
Loss函数：L1Loss()

# 输入&输出 
 输入：不同范围的随机数，20000组
 输出：不同范围的随机数，20000组
